services:
  # -------------------- ZOOKEEPER --------------------
  zookeeper:
    image: bitnami/zookeeper:3.9           # Kafka 메타데이터 관리용 ZK
    restart: always
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"         # zookeeper에 아무나 접속 허용(개발 환경 전용) -> 운영환경에선 no로 변경
    ports:
      - "2181:2181"                        # 호스트:컨테이너 포트

  # -------------------- KAFKA BROKER --------------------
  kafka:
    image: bitnami/kafka:3.6               # Kafka 브로커
    restart: always
    depends_on:
      - zookeeper                          # zk 먼저
    environment:
      KAFKA_BROKER_ID: 1                                          # 브로커 ID(단일 브로커)
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181                 # 카프카가 접속할 주키퍼 주소 지정
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092                      # 카프카가 내부에서 어떤 포트로 들어오는 연결을 수신할지 / PLAINTEXT는 암호화(TSL) 없이 통신
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092      # 카프카 위치를 클라이언트에게 알리는 주소(컨테이너 내부에서 kafka:9092로 접근 가능)
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"                 # 프로듀서나 컨슈머가 없는 토픽에 접근시 카프카가 자동으로 토픽 생성 (운영에선 fasle로 설정 권장)
      ALLOW_PLAINTEXT_LISTENER: "yes"                             # TLS 없이 허용
    ports:
      - "9092:9092"                        # 필요 시 호스트 접근용

  # -------------------- KAFKA UI --------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest   # 웹 UI로 토픽/메시지 확인
    restart: always
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    ports:
      - "8082:8080"                        # http://localhost:8082

  # -------------------- POSTGRES --------------------
  postgres:
    image: postgres:15                     # 집계 저장용 DB
    restart: always
    environment:
      POSTGRES_USER: airflow                   # DB 사용자
      POSTGRES_PASSWORD: airflow               # 패스워드
      POSTGRES_DB: airflow                   # 기본 DB명
    ports:
      - "5433:5432"                        # 호스트 5433 → 컨테이너 5432
    volumes:
      - postgres-db:/var/lib/postgresql/data  # DB 데이터 저장소
      - ./infra/init.sql:/docker-entrypoint-initdb.d/init.sql:ro # 컨테이너 최초 기동 시 init.sql 자동 실행(테이블 생성)

  # -------------------- ADMINER (DB 웹 클라이언트) --------------------
  adminer:
    image: adminer:latest
    restart: always
    depends_on:
      - postgres
    ports:
      - "8081:8080"                        # http://localhost:8081

  # -------------------- SPARK (클라이언트 모드) --------------------
  spark-master:
    image: bitnami/spark:3.5
    restart: always
    environment:
      SPARK_MODE: master # 마스터 모드
      SPARK_RPC_AUTHENTICATION_ENABLED: no                  # 스파크 노드 간 통신 인증 비활성화
      SPARK_RPC_ENCRYPTION_ENABLED: no                      # RPC(원격 프로시저 호출) 암호화 비활성화
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no            # 저장 데이터 암호 x
      SPARK_SSL_ENABLED: no                                 # SSL(브라우저와 웹 서버 간 암호화) 비활성화
    ports:
      - "7077:7077"    # master RPC
      - "8084:8080"    # master UI
    volumes:
      - ./spark-jobs:/opt/bitnami/spark-apps
      - ./spark-checkpoint:/tmp/spark-checkpoint
    depends_on: [kafka, postgres]

  spark-worker-1:
    image: bitnami/spark:3.5
    restart: always
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077   # 마스터 주소
      SPARK_WORKER_CORES: 2                         # 코어수
      SPARK_WORKER_MEMORY: 2G                       # 메모리                
    depends_on: [spark-master]
    volumes:
      - ./spark-jobs:/opt/bitnami/spark-apps
      - ./spark-checkpoint:/tmp/spark-checkpoint
    ports:
      - "8085:8081"    # worker UI (옵션)

  # -------------------- PRODUCER (API → Kafka) --------------------
  producer:
    image: python:3.11-slim                # 프로듀서 런타임
    # restart: always
    depends_on:
      - kafka
    working_dir: /app
    volumes:
      - ./producer:/app                    # 코드/요구사항 마운트
    command: ["sleep", "infinity"]         # 기본은 대기. 필요 시 수동 실행
    # 실행: docker compose run --rm producer sh -c "pip install -r requirements.txt && python run_producer.py"

  # -------------------- AIRFLOW (WEB) --------------------
  airflow-webserver:
    image: apache/airflow:2.9.1            # Airflow 웹 UI
    restart: always
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_POSTGRES_DEFAULT: ${AIRFLOW_POSTGRES_CONN}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      TZ: Asia/Seoul
    user: "${AIRFLOW_UID:-50000}:0"        # 호스트 사용자 UID를 매핑(권한 문제 방지)
    command: webserver
    ports:
      - "8083:8080"                        # http://localhost:8083
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./backups:/opt/backups             # 백업 파일 저장소 마운트(옵션)

  # -------------------- AIRFLOW (SCHEDULER) --------------------
  airflow-scheduler:
    image: apache/airflow:2.9.1
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"   # 예제 DAG 비활성화
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_POSTGRES_DEFAULT: ${AIRFLOW_POSTGRES_CONN}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      TZ: Asia/Seoul
    user: "${AIRFLOW_UID:-50000}:0"
    command: scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./backups:/opt/backups

volumes:
  postgres-db: