services:
  # -------------------- ZOOKEEPER --------------------
  zookeeper:
    image: bitnamilegacy/zookeeper:3.9           # Kafka 메타데이터 관리용 ZK
    restart: always
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"         # zookeeper에 아무나 접속 허용(개발 환경 전용) -> 운영환경에선 no로 변경
    ports:
      - "2181:2181"                        # 호스트:컨테이너 포트

  # -------------------- KAFKA BROKER --------------------
  kafka:
    image: bitnamilegacy/kafka:3.6               # Kafka 브로커
    restart: always
    depends_on:
      - zookeeper                          # zk 먼저
    environment:
      KAFKA_BROKER_ID: 1                                          # 브로커 ID(단일 브로커)
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181                 # 카프카가 접속할 주키퍼 주소 지정
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092                      # 카프카가 내부에서 어떤 포트로 들어오는 연결을 수신할지 / PLAINTEXT는 암호화(TSL) 없이 통신
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092      # 카프카 위치를 클라이언트에게 알리는 주소(컨테이너 내부에서 kafka:9092로 접근 가능)
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"                 # 프로듀서나 컨슈머가 없는 토픽에 접근시 카프카가 자동으로 토픽 생성 (운영에선 fasle로 설정 권장)
      ALLOW_PLAINTEXT_LISTENER: "yes"                             # TLS 없이 허용
    ports:
      - "9092:9092"                        # 필요 시 호스트 접근용

  # -------------------- KAFKA UI --------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest   # 웹 UI로 토픽/메시지 확인
    restart: always
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    ports:
      - "8082:8080"                        # http://localhost:8082

  # -------------------- POSTGRES --------------------
  postgres:
    image: postgres:15                     # 집계 저장용 DB
    restart: always
    environment:
      POSTGRES_USER: airflow                   # DB 사용자
      POSTGRES_PASSWORD: airflow               # 패스워드
      POSTGRES_DB: airflow                   # 기본 DB명
    ports:
      - "5433:5432"                        # 호스트 5433 → 컨테이너 5432
    volumes:
      - postgres-db:/var/lib/postgresql/data  # DB 데이터 저장소
      - ./infra/init.sql:/docker-entrypoint-initdb.d/init.sql:ro # 컨테이너 최초 기동 시 init.sql 자동 실행(테이블 생성)

  # -------------------- ADMINER (DB 웹 클라이언트) --------------------
  adminer:
    image: adminer:latest
    restart: always
    depends_on:
      - postgres
    ports:
      - "8081:8080"                        # http://localhost:8081

  # -------------------- SPARK (클라이언트 모드) --------------------
   # -------------------- SPARK MASTER --------------------
  spark-master:
    image: apache/spark:3.5.0-scala2.12-java11-python3-ubuntu
    restart: always
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_LOG_DIR=/opt/spark/logs
      - SPARK_LOCAL_DIRS=/tmp/spark-scratch
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      #### agg_1m.py 환경변수 ####
      - PG_HOST=${POSTGRES_HOST}
      - PG_PORT=${POSTGRES_PORT}
      - PG_DB=${POSTGRES_DB}
      - PG_USER=${POSTGRES_USER}
      - PG_PW=${POSTGRES_PASSWORD}
      - KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - CHECKPOINT=${CHECKPOINT}

    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "7077:7077"
      - "8084:8080"
    volumes:
      - ./spark-jobs:/opt/spark-apps
      - ./spark-checkpoint:/tmp/spark-checkpoint
    depends_on:
      - kafka
      - postgres

  # -------------------- SPARK WORKER --------------------
  spark-worker-1:
    image: apache/spark:3.5.0-scala2.12-java11-python3-ubuntu
    restart: always
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_PORT=7000
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_DIR=/opt/spark/work
      - SPARK_LOG_DIR=/opt/spark/logs
      - SPARK_LOCAL_DIRS=/tmp/spark-scratch
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    ports:
      - "8085:8081"
    volumes:
      - ./spark-jobs:/opt/spark-apps
      - ./spark-checkpoint:/tmp/spark-checkpoint

  # -------------------- PRODUCER (API → Kafka) --------------------
  producer:
    image: python:3.11-slim                # 프로듀서 런타임
    # restart: always
    environment:
    ### 환경변수 ###
      - BOOTSTRAP=${KAFKA_BOOTSTRAP}
      - TOPIC=${KAFKA_TOPIC}
      - WS_URL=wss://stream.binance.com:9443/ws/btcusdt@trade
      - SYMBOL=BTCUSDT
    depends_on:
      - kafka
    working_dir: /app
    volumes:
      - ./producer:/app                    # 코드/요구사항 마운트
    command: ["sleep", "infinity"]         # 기본은 대기. 필요 시 수동 실행
    # 실행: docker compose run --rm producer sh -c "pip install -r requirements.txt && python run_producer.py"

  # -------------------- AIRFLOW (WEB) --------------------
  airflow-webserver:
    image: apache/airflow:2.9.1            # Airflow 웹 UI
    restart: always
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_POSTGRES_DEFAULT: ${AIRFLOW_POSTGRES_CONN}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      TZ: Asia/Seoul
    user: "${AIRFLOW_UID:-50000}:0"        # 호스트 사용자 UID를 매핑(권한 문제 방지)
    command: webserver
    ports:
      - "8083:8080"                        # http://localhost:8083
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./backups:/opt/backups             # 백업 파일 저장소 마운트(옵션)

  # -------------------- AIRFLOW (SCHEDULER) --------------------
  airflow-scheduler:
    image: apache/airflow:2.9.1
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"   # 예제 DAG 비활성화
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_POSTGRES_DEFAULT: ${AIRFLOW_POSTGRES_CONN}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      TZ: Asia/Seoul
    user: "${AIRFLOW_UID:-50000}:0"
    command: scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./backups:/opt/backups
    
  dashboard:
    build:
      context: ./dashboard
    restart: always
    ports:
      - "8501:8501"                        # http://localhost:8501
    environment:
      - HOST=${HOST}
      - POSTGRES_PORT1=${POSTGRES_PORT1}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      - postgres
    volumes:
      - ./dashboard:/app

volumes:
  postgres-db: